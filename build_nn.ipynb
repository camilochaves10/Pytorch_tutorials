{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec79c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e73f538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa2ac43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b6e24a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26ce859c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.9345e-01,  2.0813e+00, -2.2888e-01, -4.8922e-01, -1.7449e+00,\n",
       "           1.1081e+00,  2.3764e+00, -2.4525e-01,  1.2118e+00, -9.5818e-01,\n",
       "           1.9357e+00,  1.0573e+00,  5.7569e-01,  2.0185e-01,  4.8955e-01,\n",
       "           8.8850e-01, -2.7712e+00, -9.0686e-01, -3.8500e-01, -2.5258e+00,\n",
       "           5.2773e-01, -7.3744e-01,  2.1549e+00, -1.7768e-02, -6.0668e-01,\n",
       "           1.5365e+00,  2.2748e-01, -9.1765e-01],\n",
       "         [ 1.3392e-01, -1.1576e+00,  3.6619e-01,  1.6462e-02, -1.0017e+00,\n",
       "           5.0247e-01,  1.0914e-01, -9.5668e-02,  5.1460e-01,  2.7856e-01,\n",
       "           8.5617e-01, -8.2553e-01,  9.5631e-01, -1.3797e+00, -1.3146e-01,\n",
       "          -5.9238e-01, -4.1412e-01,  1.2190e-01, -1.1475e-01, -6.9308e-01,\n",
       "          -1.6181e+00, -5.1963e-01, -1.0019e+00,  4.2974e-01,  1.0147e-01,\n",
       "           2.2769e+00, -3.2117e-01, -1.5179e-01],\n",
       "         [-8.2396e-01, -4.0622e-02, -8.6674e-01, -8.5109e-02, -9.7270e-01,\n",
       "          -6.0344e-01, -1.0144e+00, -7.9973e-01,  4.6056e-01, -3.0441e-01,\n",
       "          -8.4238e-01,  5.0106e-01, -6.3627e-01,  1.6889e+00,  1.0899e+00,\n",
       "          -6.9574e-01,  1.3425e+00,  4.3429e-01,  1.6218e+00, -1.2179e-01,\n",
       "           1.1071e+00,  5.4696e-01, -1.0641e-01,  7.5533e-02,  1.5261e+00,\n",
       "           8.1276e-01,  8.4065e-01,  8.2813e-01],\n",
       "         [ 7.5848e-02, -4.2871e-01, -1.8480e+00, -1.1009e-01, -3.5566e-01,\n",
       "          -8.7622e-01,  1.4414e-01, -1.0085e+00, -9.0683e-02, -1.3507e-01,\n",
       "          -2.0037e-01, -1.4289e+00, -4.5362e-03,  1.2533e+00, -1.0884e+00,\n",
       "          -1.0992e+00, -1.1281e-02,  3.7075e-01,  5.4857e-01,  1.6811e+00,\n",
       "          -1.8221e+00,  5.3965e-01,  8.0201e-01, -1.1527e+00, -1.2099e+00,\n",
       "          -5.2520e-01,  6.9209e-01,  7.0338e-02],\n",
       "         [ 8.9836e-01, -1.6191e+00,  1.4781e+00,  3.0063e-01,  2.7946e-02,\n",
       "           1.5497e+00,  2.2121e+00,  9.6618e-01,  7.6968e-01, -1.9255e+00,\n",
       "          -1.2719e+00, -2.8598e-02, -4.4462e-01,  5.7152e-01,  4.0461e-01,\n",
       "           3.8211e-01,  5.8322e-01,  1.0253e+00,  1.7511e+00,  1.3739e-01,\n",
       "           3.8737e-01,  5.4622e-02, -2.2428e-01,  4.9209e-01,  1.7585e+00,\n",
       "          -2.9124e-01, -9.8243e-01,  9.9534e-01],\n",
       "         [-1.4966e-01, -2.2271e+00,  3.6847e-01, -7.0167e-01, -5.7921e-01,\n",
       "           3.8700e-01,  6.8923e-01,  2.6938e+00,  1.1336e+00,  3.0576e-01,\n",
       "           2.8484e+00, -1.4429e+00, -1.9694e-01, -1.3222e+00,  9.2995e-01,\n",
       "           7.8962e-03,  1.3482e+00, -1.3962e+00,  3.7864e-02,  1.9322e+00,\n",
       "          -5.0727e-01, -4.9042e-01, -1.4435e+00,  4.7779e-01, -1.2076e+00,\n",
       "           1.2480e+00, -5.5130e-01, -2.5885e-01],\n",
       "         [ 1.0470e+00,  1.9911e-01, -2.2019e-01, -2.3234e+00, -7.2170e-01,\n",
       "           4.1817e-01,  2.9399e-01,  1.8366e-01,  9.5513e-03, -6.4884e-01,\n",
       "           6.9259e-01,  5.0709e-02,  6.5281e-01, -8.2264e-01, -7.4369e-01,\n",
       "          -1.3811e+00, -2.1624e+00,  7.4753e-01, -5.8080e-01,  8.1783e-01,\n",
       "           3.2422e-02,  7.8416e-01,  7.4040e-01,  3.2827e-03, -1.1559e+00,\n",
       "          -2.1720e-01,  7.1544e-01, -4.1977e-01],\n",
       "         [ 1.5031e-01,  9.8189e-02, -9.0294e-02, -1.1837e+00,  5.1390e-01,\n",
       "           1.2406e+00,  1.3677e+00,  6.4659e-01, -1.6879e+00,  6.5872e-01,\n",
       "           5.0127e-01,  4.9972e-01,  5.9634e-01, -1.7683e-01,  3.8344e-01,\n",
       "          -4.0301e-02, -9.4190e-02, -1.3598e+00,  5.9468e-01, -1.2063e+00,\n",
       "           6.5154e-01, -5.4685e-01,  5.0769e-01, -1.2595e+00,  9.5611e-02,\n",
       "           9.5916e-01,  1.4857e+00,  7.3612e-01],\n",
       "         [ 8.6526e-01,  1.2496e+00, -4.8342e-01, -5.4080e-01,  6.3385e-01,\n",
       "          -4.3289e-02,  9.8866e-01, -1.0236e+00,  1.5365e+00, -4.3148e-01,\n",
       "           8.1955e-01,  4.5542e-01, -2.0076e+00, -7.1540e-01,  1.6417e+00,\n",
       "          -1.6580e+00,  4.0994e-01,  6.6038e-01, -1.1626e+00, -1.4056e-01,\n",
       "          -1.0680e+00, -8.4872e-01, -4.7354e-01,  8.2449e-01,  7.4476e-01,\n",
       "          -9.8792e-01,  3.1969e-01,  1.3322e+00],\n",
       "         [ 3.6655e-01,  3.7873e-01, -2.4497e+00, -2.1433e-01,  5.2862e-01,\n",
       "           5.3179e-01, -1.0558e-01, -4.9307e-01, -8.9290e-02,  4.3665e-01,\n",
       "           2.5219e-01, -1.1469e+00, -9.5129e-01, -1.5092e+00,  1.5314e+00,\n",
       "          -1.4078e+00, -2.1881e-01, -2.0396e-01, -4.3971e-01,  4.4412e-01,\n",
       "           9.4827e-01, -5.4505e-01,  1.8733e+00, -2.0426e+00, -1.3675e+00,\n",
       "          -9.1592e-03, -1.2532e+00,  1.2486e+00],\n",
       "         [ 3.5563e-01,  2.7109e+00,  8.2688e-01, -1.1167e-01,  6.0750e-01,\n",
       "           1.2369e-01, -2.2972e+00, -2.7065e-01,  7.0343e-02,  5.8956e-01,\n",
       "          -1.0467e+00,  2.1339e+00, -3.8722e-01, -6.3642e-01,  1.3174e+00,\n",
       "          -9.3823e-01, -7.7655e-01, -1.3455e+00, -9.0953e-01,  1.5360e+00,\n",
       "           2.9798e-01,  8.4095e-01,  1.1530e+00,  1.0708e+00,  2.1915e+00,\n",
       "          -3.0204e-01, -2.5516e-01,  1.1629e+00],\n",
       "         [-9.1748e-01,  9.5697e-02,  4.4199e-01,  1.1676e+00,  1.5021e-01,\n",
       "          -1.2940e+00,  1.1743e+00, -4.7673e-01,  2.0896e-01, -1.2624e-02,\n",
       "          -2.1737e-01,  2.3774e-01, -1.0523e+00,  1.7740e+00, -8.5458e-02,\n",
       "          -7.7234e-01, -7.8895e-01,  2.9435e-01, -1.2759e-01, -5.7827e-01,\n",
       "          -5.2363e-01, -3.7890e-02, -8.2363e-01, -2.4022e-02, -8.9460e-01,\n",
       "           6.2039e-01, -3.7850e-01, -1.0640e+00],\n",
       "         [ 2.0312e+00,  1.1518e+00,  1.4433e+00,  6.0416e-01,  1.8720e+00,\n",
       "          -4.9338e-01, -4.8714e-02, -3.0413e-01, -7.1849e-01,  1.3386e+00,\n",
       "           1.3123e-01,  1.5045e+00,  7.0243e-01, -2.3903e+00, -2.1893e+00,\n",
       "          -2.7262e-02, -1.1732e+00, -4.0306e-01, -2.4451e+00,  7.1857e-01,\n",
       "          -5.5850e-01, -8.8572e-02,  1.1057e-01, -6.2416e-01, -7.0466e-01,\n",
       "           6.4358e-02,  8.0454e-01,  8.9983e-01],\n",
       "         [-9.5370e-01, -1.2540e+00, -2.2156e-01,  1.1310e+00, -5.8787e-02,\n",
       "           3.2235e-02,  9.8373e-01, -1.2362e+00, -8.7947e-01, -2.0279e-01,\n",
       "          -1.3120e+00, -1.8592e-02,  2.0844e-01,  3.5907e-01,  1.1632e+00,\n",
       "          -1.8122e+00,  3.3085e-01, -2.3779e+00, -1.1807e+00, -3.9306e-03,\n",
       "           1.6005e+00, -7.0265e-01,  5.4480e-01, -6.8136e-01,  1.0261e+00,\n",
       "           7.1905e-01, -1.2625e+00,  1.7174e+00],\n",
       "         [-3.5111e-02, -7.7588e-02,  9.7916e-01,  2.5433e-01,  1.7256e-01,\n",
       "          -9.8874e-01,  2.2398e-01,  9.3766e-01,  3.8376e-01,  3.0897e-01,\n",
       "          -1.0584e+00,  1.0191e+00,  4.9991e-01,  4.4089e-01,  1.2137e+00,\n",
       "           5.0862e-01, -1.0087e+00, -9.0054e-01,  8.5190e-01, -3.2861e-01,\n",
       "          -3.5920e-01, -1.1914e+00,  6.8096e-01, -1.6550e+00,  1.4390e+00,\n",
       "          -3.8582e-01,  3.5209e-01, -1.1987e+00],\n",
       "         [ 3.7181e-01, -9.7162e-01,  1.9310e-01,  6.4037e-01,  8.4742e-01,\n",
       "          -1.2258e+00, -4.7220e-01, -4.1158e-01,  6.9726e-02, -1.1635e+00,\n",
       "           4.7272e-01, -9.5094e-01,  4.0411e-01, -3.6290e-01,  8.4317e-01,\n",
       "          -4.4146e-01, -8.0248e-02, -5.9609e-01,  2.2366e-01, -1.4156e+00,\n",
       "          -1.3299e-02, -2.4515e-01, -1.8463e+00, -7.1398e-01,  1.0913e+00,\n",
       "           8.5769e-01,  2.0526e+00,  4.8113e-01],\n",
       "         [ 1.3687e+00,  1.3118e+00, -8.3834e-02,  6.3770e-01,  2.2128e+00,\n",
       "           6.6568e-01, -8.2995e-01,  8.0697e-01, -8.0552e-01, -1.4133e+00,\n",
       "          -1.6023e+00, -1.4057e+00, -1.7067e+00,  1.9281e+00,  2.8273e-01,\n",
       "           3.3027e-01, -3.3874e-01, -1.2242e-01, -8.7641e-01,  9.7108e-01,\n",
       "           3.7279e-01, -4.8380e-01, -1.3069e+00, -5.9699e-01, -6.3087e-01,\n",
       "          -3.6043e-01,  6.1750e-01,  1.2347e+00],\n",
       "         [-9.6592e-01,  1.7317e+00,  1.3988e+00, -1.8471e+00, -2.0127e+00,\n",
       "          -1.3818e+00, -1.0921e-01, -1.0881e-01,  3.2111e-01, -6.1947e-01,\n",
       "          -1.2461e+00,  4.1474e-01, -1.0658e+00, -1.5565e-01,  1.5184e+00,\n",
       "           5.6138e-01, -4.3592e-01, -2.5685e-01,  1.1848e-01, -3.3510e-01,\n",
       "          -1.9582e-01, -2.6188e+00,  8.0509e-01, -8.6131e-01, -7.4101e-02,\n",
       "           7.9925e-01, -1.0992e+00, -9.6588e-01],\n",
       "         [-6.4974e-01,  4.2093e-01,  4.7413e-01, -9.7233e-01, -1.6816e-01,\n",
       "          -9.7828e-01,  1.1097e+00, -5.6785e-01, -1.6298e-01, -2.6265e-01,\n",
       "          -8.3902e-01,  1.7218e-01,  8.8164e-01,  1.1820e+00, -2.8033e-02,\n",
       "          -4.1676e-01, -7.6835e-01,  5.5122e-01,  8.9883e-01,  4.2454e-01,\n",
       "           1.9965e+00,  1.2744e-01, -6.3771e-01,  3.4442e-01,  5.8170e-04,\n",
       "           8.5123e-01, -2.5570e+00, -9.1567e-01],\n",
       "         [-1.6953e+00,  1.3778e+00,  5.3794e-01,  1.6711e+00,  4.4366e-01,\n",
       "          -9.9423e-01, -2.7814e-01, -8.7535e-01,  1.6580e-01,  1.8715e+00,\n",
       "          -1.3912e+00,  1.3998e+00,  6.5674e-01, -6.8020e-02,  1.7855e+00,\n",
       "           1.2973e+00,  5.6973e-01,  6.5041e-01,  3.8113e-02,  4.2709e-01,\n",
       "          -7.5168e-01,  1.8639e-01,  6.9402e-01, -5.3176e-01, -1.2627e+00,\n",
       "           3.1968e+00, -3.7087e-01, -7.0504e-01],\n",
       "         [ 3.4221e-01,  5.9059e-01,  6.9778e-01, -4.9927e-01,  8.1556e-01,\n",
       "          -3.4097e-01,  1.5781e+00, -4.6497e-01, -2.2319e-01, -5.0045e-01,\n",
       "          -1.8621e+00,  1.0745e+00, -3.4921e-01,  4.7855e-02,  1.1692e+00,\n",
       "           9.3807e-01, -9.6384e-01,  5.6394e-01, -2.5591e-01, -1.1024e+00,\n",
       "          -1.0292e+00,  1.6310e+00, -1.1449e+00,  1.5560e+00, -2.8206e+00,\n",
       "           7.8424e-02, -3.1973e-01,  4.3702e-01],\n",
       "         [ 2.8780e-01,  9.6382e-02,  1.0705e-01, -1.8458e-01, -1.0006e+00,\n",
       "           8.3986e-01,  1.9316e+00, -6.0157e-01, -2.6966e-01, -1.0505e+00,\n",
       "           8.0209e-01,  3.6137e-01, -3.6047e-02, -1.0004e-01,  7.7261e-01,\n",
       "           2.1830e+00, -1.5405e-01, -1.9060e+00, -7.0485e-01, -1.4297e+00,\n",
       "           6.6506e-01,  1.4608e+00, -1.1068e+00, -6.3148e-01, -8.8405e-01,\n",
       "          -1.2620e+00,  2.7279e-01,  8.7748e-01],\n",
       "         [-9.4429e-02,  1.6883e-01,  9.2839e-01,  1.8068e+00, -6.4465e-01,\n",
       "          -1.0160e+00,  5.2701e-01, -1.2415e+00, -1.2858e+00,  8.7696e-01,\n",
       "           7.3220e-01,  9.1562e-02,  5.9823e-01, -7.4505e-01,  9.6407e-01,\n",
       "           1.1550e-01, -5.6390e-02,  8.0073e-02, -1.3109e+00,  1.3782e+00,\n",
       "           1.1117e-01, -1.2669e+00,  2.9574e-01, -1.1122e+00,  5.3627e-01,\n",
       "          -4.7308e-01, -1.9216e-01,  1.3844e+00],\n",
       "         [ 4.8460e-01, -9.4190e-01, -1.9106e-01, -9.7341e-01,  1.4249e+00,\n",
       "          -1.3587e-01,  1.2665e+00,  2.6303e+00, -4.6927e-01,  3.6833e-01,\n",
       "          -3.4524e-01, -1.0812e+00,  2.0138e-01, -1.1896e+00, -2.1252e+00,\n",
       "           1.7255e+00,  4.3865e-02, -7.7341e-01, -3.6156e-01,  2.0504e-01,\n",
       "           5.4984e-01, -8.4518e-01, -4.5042e-01, -2.0962e+00, -3.3477e-01,\n",
       "           2.8805e-01, -6.7316e-01,  4.0599e-01],\n",
       "         [-8.7946e-01, -4.6476e-01,  3.9247e-01, -3.4889e-01,  2.3364e-01,\n",
       "          -1.4257e+00, -3.8280e-01,  9.5157e-01, -5.4758e-01, -5.7372e-01,\n",
       "           3.8096e-01,  7.6444e-01, -1.9483e+00, -1.3137e+00, -4.2259e-01,\n",
       "           3.7236e-01, -5.9185e-01,  1.0256e-01, -4.9088e-01, -2.1054e+00,\n",
       "           3.2914e+00,  8.6812e-01,  2.3212e-01, -3.1000e+00,  1.5314e-01,\n",
       "           9.1551e-02, -1.1173e+00, -8.5286e-01],\n",
       "         [-6.7790e-01,  9.4384e-01, -1.8551e+00,  4.5268e-01,  1.3818e+00,\n",
       "          -9.3611e-01, -4.7848e-01,  6.6279e-01,  1.0203e-01,  1.6357e-01,\n",
       "          -3.1003e-01,  2.7923e-01,  4.2578e-01,  3.7752e-01,  8.3078e-01,\n",
       "          -1.1857e-01, -1.2824e+00,  2.1976e-02, -1.5850e+00,  7.7780e-01,\n",
       "           1.7351e-01, -1.9802e+00,  1.0652e+00, -9.5402e-01,  3.3297e-01,\n",
       "          -8.1294e-01,  5.4089e-02,  6.8157e-01],\n",
       "         [ 1.7207e+00,  1.8450e+00,  4.2626e-01, -4.1058e-01, -3.3286e-01,\n",
       "          -3.3105e-01, -4.0358e-01, -1.9065e-01, -1.0015e-01, -5.8210e-01,\n",
       "           4.5067e-01,  5.5824e-01,  3.7796e-01,  1.4364e+00, -6.0179e-01,\n",
       "          -9.4458e-01,  2.1984e-01,  5.0109e-02,  1.0431e+00, -1.7299e-01,\n",
       "          -1.1339e+00,  1.3084e+00, -1.5772e-02,  1.1197e+00, -4.8087e-01,\n",
       "           9.9035e-01, -1.0508e-01, -1.8711e-01],\n",
       "         [-8.9915e-01, -2.7566e-01, -2.0593e-01,  3.0109e+00,  1.8985e+00,\n",
       "           1.5443e-01, -4.8530e-02, -8.6483e-01, -9.4256e-02,  6.6220e-01,\n",
       "          -5.2241e-01,  1.0903e+00,  1.7613e+00, -1.5644e-01,  7.3385e-01,\n",
       "          -2.1807e+00, -2.6101e-02,  6.4715e-01,  9.5777e-01, -2.5659e-01,\n",
       "           3.2591e-01,  4.9045e-01,  9.7906e-01, -5.5447e-01,  4.6208e-01,\n",
       "           3.3789e-01, -1.2650e+00, -2.5942e-01]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(1,28,28, device = device)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96ef5e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([8])\n"
     ]
    }
   ],
   "source": [
    "logits = model(X)\n",
    "pred_prob = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_prob.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08775fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8defed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48be958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfdf0f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.1931, -0.5386, -0.1493, -0.4333, -0.3847, -0.0966, -0.3285,  0.2509,\n",
      "          0.4000,  0.0806, -0.0731, -0.1993, -0.4481,  0.2596,  0.0403, -0.1552,\n",
      "         -0.1365,  0.3221,  0.4855,  0.2462],\n",
      "        [-0.2708, -0.8799,  0.0557, -0.2140, -0.6057, -0.2967, -0.3166, -0.1734,\n",
      "          0.3975, -0.1308, -0.1001, -0.1462, -0.3875,  0.1915, -0.2594,  0.0361,\n",
      "          0.3871, -0.0312,  0.4298,  0.3458],\n",
      "        [-0.2468, -0.8953, -0.0062, -0.6087, -0.3606, -0.4032, -0.5897,  0.1715,\n",
      "          0.2538, -0.3338, -0.1557, -0.0956, -0.2841,  0.2968, -0.5802,  0.0110,\n",
      "         -0.0752,  0.4653,  0.5036,  0.4085]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2509, 0.4000,\n",
      "         0.0806, 0.0000, 0.0000, 0.0000, 0.2596, 0.0403, 0.0000, 0.0000, 0.3221,\n",
      "         0.4855, 0.2462],\n",
      "        [0.0000, 0.0000, 0.0557, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3975,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1915, 0.0000, 0.0361, 0.3871, 0.0000,\n",
      "         0.4298, 0.3458],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1715, 0.2538,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.2968, 0.0000, 0.0110, 0.0000, 0.4653,\n",
      "         0.5036, 0.4085]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02834a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4e19d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0972, 0.1176, 0.1117, 0.0861, 0.0819, 0.0886, 0.1030, 0.0980, 0.1132,\n",
       "         0.1027],\n",
       "        [0.0930, 0.1164, 0.1117, 0.0886, 0.0827, 0.0933, 0.0995, 0.0990, 0.1070,\n",
       "         0.1087],\n",
       "        [0.0981, 0.1212, 0.1150, 0.0823, 0.0855, 0.0799, 0.0978, 0.0994, 0.1072,\n",
       "         0.1137]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8b0c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0143,  0.0179, -0.0023,  ...,  0.0244,  0.0167, -0.0012],\n",
      "        [ 0.0221,  0.0228,  0.0133,  ...,  0.0191, -0.0160, -0.0113]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0231, -0.0275], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0154,  0.0219,  0.0122,  ...,  0.0002, -0.0015,  0.0401],\n",
      "        [ 0.0092, -0.0051, -0.0244,  ..., -0.0330,  0.0320,  0.0304]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0117, -0.0343], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0353,  0.0260, -0.0438,  ...,  0.0165,  0.0380, -0.0267],\n",
      "        [ 0.0434, -0.0133,  0.0125,  ...,  0.0416, -0.0413, -0.0221]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0130, -0.0417], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb89daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
